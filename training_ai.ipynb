{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#differant biometrics in this order height(cm),wingspan(cm), weight(kg),gender(0 male 1 female),age(years)\n",
    "# biometric = [185, 184,82,0,23]\n",
    "\n",
    "LEARNING_RATE = 0.1\n",
    "DISCOUNT = 0.95\n",
    "EPISODES = 1000\n",
    "SHOW_EVERY = 50\n",
    "#training proportions\n",
    "# observation={'rest':np.random.randint(100),'ut3':np.random.randint(100),'ut2':np.random.randint(100),'ut1':np.random.randint(100),'at':np.random.randint(100),'an':np.random.randint(100)}\n",
    "observation={'training':10}\n",
    "#labels of how much speed(in m/s) increase/decrease there was in each training camp\n",
    "labels=np.zeros(1000)\n",
    "for i in range (500,520):\n",
    "    labels[i]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# q_table=np.random.uniform(low=-2, high=0, size=(20,20,3)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def do_action(state, action,week,camp):\n",
    "#     #do nothing\n",
    "#     if action==0:\n",
    "#         if(week is not 12):\n",
    "#             return state,-1,False\n",
    "#         else:\n",
    "#             return state,labels[camp],True\n",
    "#     #increase training\n",
    "#     elif action==1:\n",
    "#         state['training']+=1\n",
    "#         if(week is not 12):\n",
    "#             return state,-1,False\n",
    "#         else:\n",
    "#             return state,labels[camp],True   \n",
    "#     #increase rest\n",
    "#     elif action==2:\n",
    "#         state['rest']+=1\n",
    "#         if(week is not 12):\n",
    "#             return state,-1,False\n",
    "#         else:\n",
    "#             return state,labels[camp],True   \n",
    "    \n",
    "#     #decrease training\n",
    "#     elif action==3:\n",
    "#         state['training']-=1\n",
    "#         if(week is not 12):\n",
    "#             return state,-1,False\n",
    "#         else:\n",
    "#             return state,labels[camp],True   \n",
    "    \n",
    "#     #decrease rest\n",
    "#     elif action==4:\n",
    "#         state['rest']-=1\n",
    "#         if(week is not 12):\n",
    "#             return state,-1,False\n",
    "#         else:\n",
    "#             return state,labels[camp],True   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# for camp in range (EPISODES):\n",
    "#     for week in range(12):\n",
    "#         action=np.argmax(q_table[observation['training'],observation['rest']])\n",
    "#         new_state,reward,done=do_action(observation,action,week,camp)\n",
    "#         max_future_q = np.max(q_table[(new_state['training'],new_state['rest'])])\n",
    "#         current_q = q_table[(observation['training'],observation['rest'])+(action)]\n",
    "        \n",
    "#         new_q=(1-LEARNING_RATE)*current_q+LEARNING_RATE*(reward+DISCOUNT*max_future_q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tutorial below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.47910577,  0.        ], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env= gym.make(\"MountainCar-v0\")\n",
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6  0.07]\n",
      "[-1.2  -0.07]\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "print(env.observation_space.high)\n",
    "print(env.observation_space.low)\n",
    "print(env.action_space.n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "print(len(env.observation_space.high))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20, 20]\n"
     ]
    }
   ],
   "source": [
    "DISCRETE_OS_SIZE= [20]* len(env.observation_space.high)\n",
    "print(DISCRETE_OS_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "discrete_win_size= (env.observation_space.high - env.observation_space.low) / DISCRETE_OS_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_table = np.random.uniform(low=-2,high=0,size=(DISCRETE_OS_SIZE+[env.action_space.n]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 20, 3)\n"
     ]
    }
   ],
   "source": [
    "print(q_table.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_discrete_state(state):\n",
    "    discrete_state = (state - env.observation_space.low) / discrete_win_size\n",
    "    return tuple(discrete_state.astype(np.int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "discrete_state = get_discrete_state(env.reset())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 10)\n"
     ]
    }
   ],
   "source": [
    "print(discrete_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.00085241, -0.55335292, -1.99681341])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_table[discrete_state]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.5533529195952644"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c=np.argmax(q_table[discrete_state])\n",
    "q_table[discrete_state][c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "50\n",
      "100\n",
      "150\n",
      "200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\my pc\\anaconda3\\envs\\AI\\lib\\site-packages\\ipykernel_launcher.py:22: RuntimeWarning: overflow encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250\n",
      "300\n",
      "350\n",
      "Objective reached on episode 350\n",
      "Objective reached on episode 377\n",
      "Objective reached on episode 382\n",
      "Objective reached on episode 384\n",
      "400\n",
      "Objective reached on episode 407\n",
      "Objective reached on episode 412\n",
      "Objective reached on episode 414\n",
      "Objective reached on episode 423\n",
      "Objective reached on episode 425\n",
      "450\n",
      "Objective reached on episode 451\n",
      "Objective reached on episode 474\n",
      "500\n",
      "550\n",
      "600\n",
      "650\n",
      "700\n",
      "750\n"
     ]
    }
   ],
   "source": [
    "for episode in range(EPISODES):\n",
    "    if episode % SHOW_EVERY ==0:\n",
    "        print(episode)\n",
    "        render = True\n",
    "    else:\n",
    "        render = False\n",
    "    discrete_state= get_discrete_state(env.reset())\n",
    "    done= False\n",
    "\n",
    "    while not done:\n",
    "        action = np.argmax(q_table[discrete_state])\n",
    "        new_state, reward, done, _ = env.step(action)\n",
    "        new_discrete_state = get_discrete_state(new_state)\n",
    "        \n",
    "        if render:\n",
    "            env.render()\n",
    "\n",
    "        if not done:\n",
    "            max_future_q = np.amax(q_table[new_discrete_state])\n",
    "            current_q = q_table[discrete_state +(action, )]\n",
    "\n",
    "            new_q = (1-LEARNING_RATE) * current_q + LEARNING_RATE + (reward + DISCOUNT * max_future_q)\n",
    "            q_table[discrete_state+(action, )] = new_q\n",
    "\n",
    "        elif new_state[0] >= env.goal_position:\n",
    "            print(f\"Objective reached on episode {episode}\")\n",
    "            env.render()\n",
    "            \n",
    "            q_table[discrete_state + (action,)] = 0\n",
    "\n",
    "        discrete_state=new_discrete_state\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "env.close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
